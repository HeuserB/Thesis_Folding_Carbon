{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create hdf5 datasets from a folder containing \".log\"-files\n",
    "\n",
    "## The hdf5-file contains all carbon distances for the inner-most cavity, \n",
    "## the initial and final geometry of the optimisation and the intial ond optimsed energy of the system\n",
    "\n",
    "### If the optimisation failed, the final energy will be 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "import seaborn as sns\n",
    "import h5py\n",
    "import subprocess\n",
    "import pathlib\n",
    "\n",
    "pattern_start = \"Charge\\s=\\s+0\\sMultiplicity\\s=\\s1\"\n",
    "pattern_end = \"\\s*AtmSel\"\n",
    "NA = np.newaxis\n",
    "\n",
    "pat_start = \"Type\\s+X\\s+Y\\s+Z\\s*\\n\\s*[-]+\\s*\\n\"\n",
    "pat_end = \"-[-]+\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_files(directory, extension=\".log\"):\n",
    "    file_list = []\n",
    "    for file in os.listdir(directory):\n",
    "        if file.endswith(extension):\n",
    "            file_list.append(os.path.join(directory, file))\n",
    "    return file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_functional(txt):\n",
    "    keyword = re.split(\"Done:\\s*E\\(\",txt)[1]\n",
    "    keyword = re.split(\"\\)\\s*=\\s*\",keyword)[0]\n",
    "    \n",
    "    if bool(re.search(\"Opt=\",txt)) == False:\n",
    "        functional = re.split(\"R\",keyword)[-1]\n",
    "        functional = re.sub(r'([A-Z])\\1', lambda pat: pat.group(1).lower(), str(functional))\n",
    "        basis_set = re.split(\"Standard\\sbasis:\\s+\",txt)[1]\n",
    "        basis_set = re.split(\"\\s\",basis_set)[0]\n",
    "\n",
    "    else:\n",
    "        tmp = re.split(\"Opt=\",txt)[1]\n",
    "        tmp = re.split(\"\\s\",tmp)[1]\n",
    "        functional, basis_set = re.split(\"/\",tmp)\n",
    "    keyword =\"E\\(\" + keyword + \"\\) =\\s+\"\n",
    "    return functional, basis_set, keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_energies(txt, functional):\n",
    "    pattern = re.compile(\"Normal termination of Gaussian\")\n",
    "    pattern2 = re.compile(\"Error termination request processed by link 9999.\")\n",
    "\n",
    "    p = functional + \"\\)\"\n",
    "    p = re.compile(p, re.IGNORECASE)\n",
    "    \n",
    "    try:\n",
    "        tmp_init = re.split(p, txt)[1]\n",
    "    except:\n",
    "        return None\n",
    "    tmp_init = re.split(\"\\s*=\\s*\",tmp_init)[1]\n",
    "    tmp_init = re.split(\"\\s*\",tmp_init)[0]\n",
    "    \n",
    "    if bool(re.search(pattern,txt)) == True:\n",
    "        tmp_final = re.split(p,txt)[-1]\n",
    "        tmp_final = re.split(\"\\s*=\\s*\",tmp_final)[1]\n",
    "        tmp_final = re.split(\"\\s+\",tmp_final)[0]\n",
    "\n",
    "    else:\n",
    "        tmp_final = \"0.0\"\n",
    "        \n",
    "    E_init = float(tmp_init)\n",
    "    E_final = float(tmp_final)\n",
    "    return E_init, E_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_atoms(txt):\n",
    "    tmp = re.split(\"Multiplicity\\s=\\s[0-9]\",txt)[-1]\n",
    "    tmp = re.split(\"\\s+AtmSel\",tmp)[0]\n",
    "    atoms = re.sub(\"[^a-zA-Z]\", '', tmp)\n",
    "    atoms = re.findall('[A-Z][^A-Z]*', atoms)\n",
    "    return atoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_geometry_init(txt,pattern_start=pattern_start, pattern_end=pattern_end):\n",
    "    geometries = re.split(pattern_start,txt)[1]\n",
    "    geometries = re.split(pattern_end, geometries)[0]\n",
    "    geometries_array = []\n",
    "    for geometry in geometries.strip().splitlines():\n",
    "        tmp = re.split(\"[A-Z][a-z]*\\s+\",geometry)[1]\n",
    "        tmp_np = np.fromstring(tmp,sep=' ')[-3:].reshape(3)\n",
    "        geometries_array.append(tmp_np)\n",
    "    return np.array(geometries_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_geometry_final(txt,pattern_start=pat_start, pattern_end=pat_end):\n",
    "    try:\n",
    "        geometries = re.split(pattern_start,txt)[-1]\n",
    "    except:\n",
    "        return None\n",
    "    geometries = re.split(pattern_start,txt)[-1]\n",
    "    geometries = re.split(pattern_end, geometries)[0]\n",
    "    geometries = re.sub(\"\\s+[0-9]+\\s+[0-9]+\\s+[0-9]+\\s+\", \",\", geometries)\n",
    "    geometries = re.sub(\"\\n\",\"\", geometries)\n",
    "    geometries = re.sub(\"\\s+\",\",\", geometries.strip())\n",
    "    geometries = geometries[1:]\n",
    "    tmp_np = np.fromstring(geometries, sep=',').reshape(-1,3)\n",
    "    return tmp_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def three_dist(geometry):\n",
    "    dist_a, dist_b, dist_c = np.linalg.norm(geometry[15] - geometry[35]) , np.linalg.norm(geometry[21] - geometry[22]), np.linalg.norm(geometry[28] - geometry[29])  \n",
    "    mean_dist = np.mean([dist_a,dist_b,dist_c])\n",
    "    return np.round(mean_dist,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def form_datasets(directory, title, output_directory = \"./\"):\n",
    "    file_list = list_files(directory)\n",
    "    # create a list of all the dataset that need to be created, with functionals, halogen, initial angle and basis set\n",
    "    data_set_list = np.array([])\n",
    "    hdf_files = []\n",
    "    geometry_list = []\n",
    "    functionals = []\n",
    "    basis_sets = []\n",
    "    radii,  E_inits, E_finals = [], [], []\n",
    "    for file in file_list:\n",
    "        print(file)\n",
    "        f = open(file,'r')\n",
    "        txt = f.read()\n",
    "        f.close()\n",
    "        if bool(re.search(\"Problem\\swith\\sthe\\sdistance\\smatrix\",txt)) == True:\n",
    "            print(\"Small distance error\")\n",
    "            continue\n",
    "        if bool(re.search(\"A\\ssyntax\\serror\\swas\\sdetected\",txt)) == True:\n",
    "            print(\"Syntax error\")\n",
    "            continue\n",
    "        if bool(re.search(\"Small\\sinteratomic\\sdistances\\sencountered\", txt)) == True:\n",
    "            print(\"Small distance in file: %s\" %file)\n",
    "            continue\n",
    "        if bool(re.search(\"NtrErr\\sCalled\\sfrom\\sFileIO\",txt)) == True:\n",
    "            print(\"Some weird error\")\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            functional, basis_set, keyword = read_functional(txt)\n",
    "        except:\n",
    "            base = re.split(\"\\+\",file)[0]\n",
    "            base += \"* \"\n",
    "            path = str(pathlib.Path().absolute())\n",
    "            command = \"mv \" + path + \"/\" + base + path + \"/\" + directory + \"failed/\"\n",
    "\n",
    "            result = os.popen(command)\n",
    "            \n",
    "        new_name = file + \"_failed\"\n",
    "           \n",
    "        try:\n",
    "            E_init, E_final = read_energies(txt, functional=functional)\n",
    "            geometries_init = read_geometry_init(txt)\n",
    "            geometries_final = read_geometry_final(txt)\n",
    "        except:\n",
    "            print(\"Failed to get data from file: %s\" %file)\n",
    "            os.rename(file, new_name)\n",
    "            continue\n",
    "            \n",
    "\n",
    "        geometries = np.vstack([geometries_init[NA,...], geometries_final[NA,...]])\n",
    "        data_set = title\n",
    "\n",
    "        if data_set not in data_set_list:\n",
    "\n",
    "            data_set_list = np.append(data_set_list,data_set)\n",
    "            filename = output_directory + data_set + \".h5\"\n",
    "            hdf_files.append(h5py.File(filename, 'w'))\n",
    "            E_inits.append(np.array([]))\n",
    "            E_finals.append(np.array([]))\n",
    "            functionals.append(functional)\n",
    "            basis_sets.append(basis_set)\n",
    "            geometry_list.append(np.empty([1,2,geometries.shape[-2], geometries.shape[-1]]))\n",
    "            radii.append(np.array([]))\n",
    "            \n",
    "        idx = np.where(data_set_list == np.array(data_set))[0][0]\n",
    "        d_CC = three_dist(geometries_init)\n",
    "        radii[idx] = np.append(radii[idx],d_CC)\n",
    "        E_inits[idx] = np.append(E_inits[idx],E_init)\n",
    "        E_finals[idx] = np.append(E_finals[idx],E_final)\n",
    "        geometry_list[idx] = np.append(geometry_list[idx], geometries[NA,...], axis=0)\n",
    "\n",
    "    \n",
    "    for i in range(len(data_set_list)):\n",
    "        id_sort = np.argsort(radii[i])\n",
    "        radii[i] = radii[i][id_sort]\n",
    "        E_inits[i] = E_inits[i][id_sort]\n",
    "        E_finals[i] = E_finals[i][id_sort]\n",
    "        geometry_list[i] = geometry_list[i][1:,...]\n",
    "        geometry_list[i] = geometry_list[i][id_sort]\n",
    "        \n",
    "        data_set = data_set_list[i]\n",
    "        hdf_files[i].create_dataset(\"radii\",data=radii[i])\n",
    "        hdf_files[i].create_dataset(\"E_init\", data=E_inits[i])\n",
    "        hdf_files[i].create_dataset(\"E_final\", data=E_finals[i])\n",
    "        hdf_files[i].create_dataset(\"functional\", data=functionals[i])\n",
    "        hdf_files[i].create_dataset(\"basis_set\", data=basis_sets[i])\n",
    "        hdf_files[i].create_dataset(\"geometries\", data=geometry_list[i])\n",
    "        print(\"Written HDF5 file for Carbon distances distances:\")\n",
    "        [print(str(i)) for i in radii]\n",
    "        \n",
    "        hdf_files[i].close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#form_datasets(\"F/hinge_0/\", title = \"hdf5/hinge_0_F\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#form_datasets(\"Cl/\", title = \"hdf5/hinge_0_Cl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#form_datasets(\"F/hinge_0_inside/\", title = \"hdf5/hinge_0_F_inside\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
